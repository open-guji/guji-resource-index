# 古籍网站信息调研

按照 `websites/模板.md` 的格式，调研并完善一个古籍网站的信息文档。

目标文件：`websites/$ARGUMENTS.md`

## 文档结构

每个文档分为两部分，用 `---` 分割线分隔：

### 第一部分：用户文档（分割线以上）

面向普通用户，语言简洁易懂，**不含技术细节**（不要出现 API、JSON、正则、CSS 选择器等）。

包含以下板块：

1. **标题 + 一句话介绍 + 基本信息列表**
   - 一句话说清楚这是什么网站、谁建的、收了什么
   - 列表项：网站链接、分享协议、规模数量、资源类型、是否支持 IIIF

2. **搜索与浏览**
   - 用日常语言描述怎么搜索、能按什么筛选
   - 给出搜索页面的链接
   - 说明是否需要注册登录

3. **每本书能看到什么**
   - 用表格列出详情页上的元数据字段（字段名 | 说明 | 示例值）
   - 补充说明：能否在线翻阅、有无 PDF、有无全文文字、特色功能

4. **示例**
   - 1-2 个可直接点击的示例链接

### 第二部分：开发者文档（分割线以下）

面向程序员，包含所有技术细节。以 `# 开发者文档` 作为标题。

包含以下板块：

1. **URL 结构**
   - 各层级页面的 URL 模式（详情页、阅读页、图片页、IIIF manifest 等）
   - 每个参数的含义

2. **搜索 API**（如果有）
   - 请求方式、URL、参数、响应结构
   - 无公开 API 则注明

3. **元数据获取**
   - 传统网站：HTML 结构、CSS 选择器、正则表达式
   - SPA 网站：API 端点、请求头、请求方式、响应 JSON
   - 有 JSON API 的网站：API URL 和响应格式
   - **字段映射表**：中文字段名 → 提取方式（CSS 选择器 / JSON 路径 / 正则）

4. **下载**
   - IIIF：manifest 结构、Image API 格式、从 manifest 到图片 URL 的流程
   - bookget：源码链接、关键逻辑
   - 自有 API：图片 URL 构成、认证方式、保护措施、必需请求头

## 效率原则

- **每个网站的调研时间控制在 10 分钟以内**
- 不要过度深入：做 2-3 次 web search + 1-2 次页面抓取即可，够写文档就停
- **遇到阻碍（WAF、403、SPA 无法抓取等）立即放弃该步骤**，用"待确认"标注，不要反复尝试
- 优先从 web search 结果和 bookget 源码获取信息，不必亲自验证每个字段
- 元数据字段表如果无法从页面确认，可根据平台类型（Islandora/DSpace/自研等）给出合理推测并标注
- 一次性写入完整文档，不必分步写入

## 工作流程

按以下步骤快速完成，一次性写入完整文档。

### 第一步：基本信息 → 写入用户文档的标题和基本信息

需要收集：
- **一句话介绍**：这个网站/平台是什么，谁建设的，定位是什么
- **网站链接**：主页面URL
- **分享协议**：查找网站的版权声明/使用协议页面，常见的有：
  - CC BY-SA 4.0 等 Creative Commons 协议
  - 公有领域 / Public Domain
  - 自定义协议（如"免费开放·禁止商用"）
  - 注意：链接到协议原文页面
- **规模**：约多少本/部古籍，多少卷册
- **资源类型**：善本、普通古籍、拓片、地方志等

**查找方式**：
1. 先 web search 该网站的介绍、新闻报道
2. 查看网站自身的"关于"页面或使用协议页面
3. 新闻报道中通常会提到馆藏数量

**写入时机**：收集完成后立即写入文件的头部（用户文档部分），同时预留后续板块的空标题。

### 第二步：搜索方式 → 写入用户文档的"搜索与浏览"

需要记录：
- 搜索/检索页面的 URL
- 是否有高级搜索
- 搜索支持哪些筛选维度（著者、年代、分类等）
- 是否需要注册登录

用户文档部分用日常语言写，不要写 URL 参数格式。
如果发现有 JSON API（如 Blacklight 的 `.json` 后缀），先记下来，后续写入开发者文档。

### 第三步：示例网址 + 元数据字段 → 写入用户文档的"每本书能看到什么"和"示例"

这一步需要找到真实可用的示例 URL，并打开页面查看有哪些元数据字段。

**信息来源（按优先级）**：
1. **bookget wiki**：https://github.com/deweizhu/bookget/wiki/04.%E5%8F%AF%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99URL
2. **bookget IIIF wiki**：https://github.com/deweizhu/bookget/wiki/05.IIIF%E6%A0%87%E5%87%86%E7%BD%91%E7%AB%99URL
3. **直接访问网站**，搜索一本常见古籍（如《论语》《史记》《周易》），从搜索结果中获取 URL

**注意事项**：
- 古籍资源通常有多个层级：作品 → 卷/册 → 页面/图片
- 每个层级都应该给出一个示例 URL
- 记录 URL 中各参数的含义（后续写入开发者文档）
- 如果网站有多个子平台或不同版本，都要记录

**写入时机**：
- 用户文档的"每本书能看到什么"：用表格列出字段名、说明、示例值
- 用户文档的"示例"：给出 1-2 个可点击链接
- 开发者文档此时先不写

### 第四步：技术分析 → 写入开发者文档的"URL 结构"、"搜索 API"、"元数据获取"

这一步深入分析技术细节。

**分析方法**：
1. 用 WebFetch 抓取示例页面（注意：部分中国网站可能无法从海外访问，或使用 SPA 动态渲染）
2. **如果 WebFetch 失败（ECONNREFUSED），改用 WSL curl**：`wsl -e curl -s -L "http://..."` —— 本机 WSL 环境通常可以正常访问国内网站
3. 如果 WebFetch 和 curl 都无法获取有效内容，查看 bookget 源码中的解析逻辑：https://github.com/deweizhu/bookget/tree/main/app
4. 记录关键的 HTML 标签、CSS class/id、或 API 端点
5. 给出提取方法（正则表达式、CSS 选择器、或 API 调用方式）

**元信息提取要点**：
- 元数据通常集中在一个 `<div>` 区域，以重复的标签结构呈现（如 `<label>` + `<span>` 键值对）
- 先用 curl 抓取完整 HTML，用 grep 过滤关键 class 名（如 `class="tt"`, `class="title"` 等）定位元数据区域
- 然后提取 HTML 中 500~1000 行左右的核心区域细看
- 注意 hidden input 字段中也常包含 title、author、identifier 等信息
- 如果是 SPA 网站，元数据通过 API 返回（通常是 JSON 格式），需要找到对应的 API 端点

**写入时机**：写入分割线以下的开发者文档。包括：
- URL 结构（各层级 URL 模式 + 参数说明）
- 搜索 API（如果有）
- 元数据获取（HTML 解析方式 或 API 方式 + 字段映射表）

### 第五步：下载方式 → 写入开发者文档的"下载"

**检查清单**：
1. **是否支持 IIIF 协议？**
   - 查看 bookget IIIF wiki：https://github.com/deweizhu/bookget/wiki/05.IIIF%E6%A0%87%E5%87%86%E7%BD%91%E7%AB%99URL
   - 如果支持，记录 manifest URL 格式和 Image API 格式
   - 给出从 manifest 到图片 URL 的完整流程
2. **bookget 是否支持？**
   - 查看 https://github.com/deweizhu/bookget/tree/main/app 下是否有对应的 .go 文件
   - 如果有，阅读源码，提取关键的 API 端点和下载逻辑
   - 记录 bookget 源码文件的链接
3. **自有 API / 其他下载方式**
   - 图片 URL 的构成方式
   - 是否需要认证（Cookie / Token / Referer 校验）
   - 图片是否有保护措施（水印、安全头标记等）
   - 必需的 HTTP 请求头

**写入时机**：写入开发者文档的"下载"部分。同时回到用户文档头部，更新是否支持 IIIF / bookget 的信息。

## 经验教训

- 很多中国古籍网站是 SPA（单页应用），HTML 源码中没有实际内容，数据通过 JS 异步加载
  - 这种情况下要找到后端 API 端点，记录请求方式（GET/POST）、参数、返回格式
- bookget 的 Go 源码是非常好的参考，它已经逆向分析了大量网站的 API
  - **但 bookget 主要关注下载逻辑，通常不提取书籍元信息** —— 元信息解析需要自己分析 HTML/API
- WebFetch 对国内网站经常返回 ECONNREFUSED，优先用 `wsl -e curl` 代替
- 中国网站的 HTML 中常有大量条件注释（如不同专题库显示不同字段），注意从注释中辨别实际渲染逻辑
- 不同子库/专题资源库的元数据字段可能不同，尽量多看几个不同 indexName 的页面
- 国内图书馆网站通常不支持 IIIF，使用自有 API；日本、欧美图书馆更多支持 IIIF
- 部分网站的图片有保护措施：水印、`###SECURED_IMAGE###` 头标记、Referer 校验等
- 注意记录必需的 HTTP 请求头（User-Agent、Referer、自定义认证头等）
- bookget 源码中的 `getBody()` / `getCanvases()` / `download()` 等函数是理解下载逻辑的关键入口

## 参考资料

- 模板：`websites/模板.md`
- 已完成的示例：`websites/哈佛大学图书馆.md`（结构最完整的参考）
- bookget wiki（网站URL）：https://github.com/deweizhu/bookget/wiki/04.%E5%8F%AF%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99URL
- bookget wiki（IIIF）：https://github.com/deweizhu/bookget/wiki/05.IIIF%E6%A0%87%E5%87%86%E7%BD%91%E7%AB%99URL
- bookget 源码：https://github.com/deweizhu/bookget/tree/main/app

## 输出要求

- 每完成一步就立即写入文件，让用户可以实时看到进度
- 用户文档部分：语言简洁，不含技术术语，给出真实示例值
- 开发者文档部分：信息具体、可操作，URL 参数逐一解释，给出具体的选择器或正则
- 不确定的信息要标注"待确认"
